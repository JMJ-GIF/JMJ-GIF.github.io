---
layout: post
title: 실시간 데이터 스트리밍 아키텍쳐 비교하기
categories: 
  - contents
sitemap: false
hide_last_modified: true
related_posts:
---
![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=http%3A%2F%2Fhits.dwyl.comjmj-gif%2FJMJ-GIF.github.io.svg{{ page.url }}&count_bg=%2379C83D&title_bg=%23555555&icon=jenkins.svg&icon_color=%23E7E7E7&title=%EC%A1%B0%ED%9A%8C%EC%88%98&edge_flat=true)

## 들어가며
세상의 모든 서비스들이 app 으로 출시되면서 요새 어딜가나 실시간 데이터를 다루는 것이 중요하게 받아들여지고 있습니다. DA라는 직무로 근무하며, 특히나 로그와 관련된 부분이 주로 실시간으로 DB에 저장되고 이를 가공하고 분석하는 일을 담당했었습니다. 로그는 각기 다른 유저들의 무작위적 행동의 합이기 때문에, 종종 예상할 수 없는 오류들이 일어나기 마련입니다. 데이터 처리의 전 과정의 가장 마지막인 “분석”을 담당하는 사람으로써, 이러한 문제를 탐지하는 것에 큰 관심을 가지고 있습니다. 

분석 단계에서의 집계오류가 아니라면 데이터 파이프라인을 차근차근 하나씩 거슬러 올라가야 합니다. 그 때마다 중간 단계에서 데이터를 이어주는 스트리밍 서비스인 Apache Kafka 와 Kinesis 에 대해서 자주 접하게 되었습니다. 어깨너머로 추상적으로 익혔던 두 가지 개념에 대해서 공부해보고, 비교한 내용들을 여러분에게 소개하고자 합니다. 본 포스트는 [패스트 캠퍼스의 7개 프로젝트로 완벽하게 끝내는 AWS 데이터 파이프라인 구축](https://fastcampus.co.kr/data_online_awspipeline) 강의를 보고, 발전시켜 작성한 글 임을 밝힙니다.

## Kafka 란 무엇이고, 어떤 구조를 가지고 있을까?
![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/1.png "Kafka 구조")

출처: [Kafka 구조](https://techblog.gccompany.co.kr/apache-kafka%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EC%97%AC-eda-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0-bf263c79efd0)

Kafka는 **분산 메시징 시스템**으로, **실시간 데이터 스트리밍**을 위한 **Pub/Sub(발행/구독)** 아키텍처를 기반으로 설계되었습니다.

- **Producer** : 데이터를 생성하여 Kafka의 특정 Topic으로 전송하는 역할을 합니다. 데이터는 Partition에 분산 저장되어 병렬 처리가 가능해집니다.
- **Topic** : 데이터를 논리적으로 분류하는 단위로, 내부적으로 Partition으로 나뉘어 데이터가 저장됩니다.
- **Partition** : Topic의 물리적 데이터 저장 단위로, 데이터의 병렬 처리와 클러스터 확장성을 지원합니다.
- **Broker** : Kafka 서버로 데이터를 저장하고 클라이언트 요청을 처리하며, 리더-팔로워 구조로 데이터 복제를 관리합니다.
- **Consumer** : Kafka에서 데이터를 읽어오는 클라이언트로, Consumer Group을 활용해 병렬로 데이터를 처리할 수 있습니다.
- **Zookeeper** : 클러스터의 메타데이터와 상태를 관리하며, 리더 선출과 같은 조율 작업을 담당합니다.

다수의 Producer와 Consumer가 동시에 존재하며, 서로 독립적으로 데이터를 생성하고 소비할 수 있습니다. Producer는 데이터를 여러 Partition으로 분산 저장하여 병렬 처리를 지원하고, Consumer는 Consumer Group을 통해 데이터를 효율적으로 분배받아 처리할 수 있습니다.

## Kafka 로컬에서 실습해보기
로컬 실습환경은 아래와 같습니다.

- Mac OS Sonoma 14.3
- OS/Arch : darwin/arm64
- Apple M2
- Docker version 24.0.2
- Docker Desktop 4.21.1

~~~bash
docker-compose up
~~~

[실습 레포지토리](https://github.com/JMJ-GIF/kafka-practice) 에 예제 코드를 넣어두었으며, 로컬에서 Docker Demon을 실행하고 docker-compose.yml 파일을 실행하면 실습환경이 구축됩니다.

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/2.png "dockers")

docker-compose.yml 파일을 실행하면 총 여섯개의 컨테이너가 로컬에 올라가고, 아래와 같은 구조로 일련의 작업들이 실행되게 됩니다.

**[producer]**

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/3.png "producers")

- producer 에서는 데이터를 보냅니다.
- KafkaProducer python sdk 를 통해 kafka 에게 ‘producer_id’, ‘id’, ‘timestamp’, ‘value’ 총 4개의 정보를 가진 데이터를 kafka 내에 
존재하는 multi-test-topic 으로 전송했습니다.

**[kafka]**

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/4.png "kafka-ui")

- localhost:8080 에 접속하면, kafka-ui 를 통해 producer가 보낸 실시간 데이터를 확인할 수 있습니다. 
- multi-test-topic 내부에 총 1개의 파티션이 20개의 메시지를 offset 순서대로 저장하고 있음을 알 수 있습니다.

**[Consumer]**

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/5.png "consumer")

- Consumer 는 multi-test-topic 내부에 존재하는 데이터를 offset=0 부터 순차적으로 가져오게 설계했습니다.
- Producer 에서 보내고 있는 데이터를 그대로 잘 받고 있음을 알 수 있습니다.

**[Logstash]**

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/6.png "logstash1")
![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/7.png "logstash2")

- 조금 다른 예시로 logstash 를 또다른 Consumer 라고 가정하고 데이터를 받도록 해보았습니다. 
    - 바로 위에서 실습한 Consumer Group 과 동일하게 설정하면 데이터를 온전히 받지 못할 수 있기 때문에, Consumer Group 을 다르게 설정하여 데이터를 받아왔습니다. 
- 또한 logstash 에는 “processed_by = logstash” 를 추가하여 데이터를 변형하도록 지시했고, ``/usr/share/logstash/data/kafka_output.log `` 에 데이터를 떨구도록 설정하였습니다.

## Kinesis 란 무엇이고, 어떤 구조를 가지고 있을까?
![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/8.png "Kinesis 구조")

출처: [Kinesis 구조](https://www.smileshark.kr/post/we-live-in-the-serverless-era-the-serverless-pipelines-without-kinesis)

Kinesis 도 Kafka 와 마찬가지로 **분산 메시징 시스템**으로, 데이터를 Producer 가 Stream에 기록하고, Consumer가 해당 데이터를 처리하도록 설계되었습니다. 

- **Producer** : 데이터를 생성하여 Kinesis Stream으로 전송합니다. Partition Key와 Data Blob을 포함한 Record를 생성합니다.
- **Record** : Producer가 전송하는 데이터 단위를 의미합니다.
- **Stream :** 데이터를 처리하고 저장하는 논리적 단위를 의미합니다.
- **Shard** : Kinesis의 병렬 처리 단위로 데이터를 저장합니다. Shard 내부에서 Sequence Number로 데이터의 순서를 보장합니다.
- **Hash Function** : Partition Key를 해시 함수로 계산해 Shard에 분배합니다. 동일한 Partition Key의 데이터는 같은 Shard로 매핑합니다.
- **Broker** : Kafka 서버로 데이터를 저장하고 클라이언트 요청을 처리하며, 리더-팔로워 구조로 데이터 복제를 관리합니다.
- **Consumer** : Shard에서 데이터를 읽고 처리하는 주체입니다. 데이터를 순차적으로 소비하며 병렬 처리가 가능합니다.

## Kinesis AWS 환경에서 실습해보기
![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/9.png "Kinesis 실습")

AWS 실습환경은 아래와 같습니다.

- 이미 EC2 서버가 있다고 가정함.
    - Producer 역할로서 데이터를 보내는 역할
- 최종적으로 EC2 에서 보낸 데이터를 S3로 보내는 것을 목표로 함.
    - Consumer 역할로서 데이터를 받는 역할
- **[API Gateway -  Kinesis - Firehose]** 을 묶어 데이터 스트리밍 파이프라인을 구성함
    - 여러 Producer 가 있다고 할 때, API Gateway 가 데이터 전송 이외에도 아래의 역할을 추가로 수행할 수 있기 때문에 Kinesis 와 함께 사용하면 좋음
        - 보안 (인증/인가, 트래픽 제어, 데이터 유효성 검증)
        - HTTP 요청 처리
        - 데이터 포맷 변환 (파이프라인 형태에 맞게 변환 가능)
        - 여러 Producer 의 요청을 처리할 수 있음
    - 여러 Consumer 가 있다고 할 때, Firehose 가 데이터 전송 이외에도 아래의 역할을 추가로 수행할 수 있기 때문에 Kinesis 와 함께 사용하면 좋음
        - 데이터를 압축 처리해서 전송 비용을 절감할 수 있음
        - 데이터를 일정 크기로 묶어 배치 형태로 전송이 가능함

**[API Gateway]**

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/10.png "api-gateway1")

- 실습은 REST API 형태로 진행하며, 안내에 맞추어 API Gateway 를 만들어줍니다. 

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/11.png "api-gateway2")

- 이후 본인이 원하는 이름으로 리소스를 만들어줍니다. 저 같은 경우는 v1 이라는 이름으로 리소스를 생성했습니다.

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/12.png "api-gateway3")

- 다음으로 메서드를 생성했습니다. 이번 실습에서는 POST 로 받아 POST 방식으로 Kinesis 에 전달할 것이기 때문에 맞춰서 메서드를 설정해주면 됩니다.
- 실행 역할은 IAM 에서 API Gateway 에게 부여하고 싶은 Kinesis 역할을 할당하여 생성후 적어주시면 됩니다. 작업 이름은 대소문자를 구분하기 때문에 잘 구분해서 지어주시면 되겠습니다!

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/13.png "api-gateway4")

- 이후에, 넣고 싶은 데이터 형식에 맞춰서 헤더 파라미터와 매핑 탬플릿을 맞춥니다.
- 저는 my_practice 라는 이름으로 Kinesis stream을 만들거라서, StreamName 을 그렇게 설정했습니다.

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/14.png "api-gateway5")

- 모든 것을 설정하고 배포하면, 스테이지 > POST 에 들어갔을때 Endpoint 를 얻을 수 있습니다. 
- 해당 주소로 데이터를 보내면 API Gateway 가 데이터를 Kinesis 로 보내게 됩니다.

**[Kinesis]**

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/15.png "kinesis")

- 이후, Kinesis 로 가서 my_practice 로 Stream 이름을 지어주고 샤드는 1개로 설정후 Stream 을 생성해주었습니다.

**[Firehose]**

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/16.png "firehose")

- Firehose 도 간단합니다. Kinesis 에서 받아 S3로 데이터를 보낼것이기 때문에 대상을 S3로 설정해주면 됩니다.
- 저는 aws_practice 라는 이름의 s3에 rawdata 라는 폴더로 Kinesis 로 부터 데이터를 받아 저장하려고 합니다.

**[Test]**

~~~bash
curl -d "{\"value\":\"86\",\"status\":\"active\", \"topic\":\"Data Engineering\"}" -H "Content-Type: application/json" -X POST {myURL}

>> {"SequenceNumber":"49657959388065273069134773629801011932593840217175097346","ShardId":"shardId-000000000000"}
~~~

- 이제 데이터를 보내봅시다! 위 명령어로 보내면 데이터가 저장된 SequnceNumber 와 ShardId 가 나옵니다.
- ShardId는 저장된 컨테이너의 위치, SequnceNumber는 컨테이너 내에 저장된 구체적인 주소입니다.

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/19.png "test")

- Kinesis 에서 확인해보았더니, 데이터가 아주 잘 들어와 있음을 확인할 수 있었습니다.

![800x400](../../assets/img/post_img/실시간%20데이터%20스트리밍%20아키텍처%20비교하기/20.png "test2")

- S3 에서도 데이터가 잘 들어왔습니다!

## 그렇다면, 왜 굳이 이렇게 복잡한 플로우를 가져야 하나?

그렇다면, 왜 굳이 이렇게 복잡한 과정을 거쳐서 라이브 데이터를 받아야 하는걸까요?

ec2에서 바로 S3로 데이터를 보내면 안되는걸까요? 혹은 Consumer 가 직접 Producer 에게 데이터를 직접 보내면 안되는걸까요?

아래에 그 이유를 정리해보았습니다.

- 첫 번째. 의존성 문제가 생길 수 있습니다.
    - Producer 와 Consumer 사이에 의존성이 생긴다면, 어느 한 쪽에 장애가 나면 다른 한 쪽도 장애가 나게 됩니다.
    - Producer 가 데이터를 잘못 보낸다면 Consumer 에게 잘못된 데이터가 바로 전송됩니다.
    - 만약 중간에 이를 처리해주는 허브가 있다면 Producer 가 장애가 나더라도, Consumer 는 허브에 존재하는 정상 데이터만 읽어오면 됩니다.

- 두 번쨰. 실시간 처리가 어렵습니다.
    - 직접 데이터를 보낸다면 S3에 저장하는 동시에 분석하기 좋은 포맷으로 변환할 수 없습니다. 
    - 즉, Consumer 가 데이터를 수신한 이후 별도의 작업을 거쳐야 합니다.
    - 중간에서 이를 처리한다면 Consumer 가 데이터를 수신하기 전에 다양한 작업들이 선행될 수 있습니다. 
      - 전처리, 실시간 분석, 모니터링, 알림 등

- 세 번째. 대규모 데이터 관리를 관리하기에 비효율적입니다.
    - 직접 전송해야하는 데이터가 굉장히 크다면, S3나 Consumer로 데이터를 보내는 작업이 매우 비효율적입니다.
    - Producer가 일일이 압축해서 보내야 할텐데 이는 매우 번거로운 작업입니다.
    - 중간에서 데이터를 압축해서 보내주면 전송 속도 단축, 네트워크 부하 감소, 비용 감소 등의 효과가 있습니다.

- 네 번째. 데이터 유실 위험이 있습니다.
    - 데이터를 직접 보내다가 네트워크 장애가 나면, 복구가 불가합니다.
    - 중간 단계가 존재한다면 네트워크 장애가 나더라도 저장된 값으로 대응이 가능합니다.

- 다섯 번째. 확장성을 가질 수 있습니다.
    - Producer가 Consumer 에게 1대1로 보내는 경우면 괜찮겠지만, 다수의 Producer 가 다수의 Consumer 가 연결되어야 하는 상황이면 어떻게 될까요? 
    - 서비스는 매우 복잡해지게 될 것입니다.
    - 구독 시스템을 통해 중앙 일원화 할 수 있고, 구독자들이 많아진다면 중앙에서의 컴퓨팅 파워를 늘리면 유연하게 대응이 가능합니다.
      - Kinesis 는 Shard 를 늘리면 됩니다.
      - Kafka 는 Broker 를 늘리면 됩니다.


## Kafka 와 Kinesis 는 무엇이 다를까?

공통점은 무엇이고, 차이점은 무엇일까요? 우리는 어떤 서비스를 사용해야할까요?

- 공통점
    - 데이터 분산 및 병렬처리
        - Kinesis 는 Shard 라는 개념을 통해, 스트림을 분산하여 데이터를 병렬로 처리합니다.
        - Kafka는 Partition 라는 개념을 통해, 여러 broker에 분산하여 병렬로 처리합니다.
    - 확장성
        - Kinesis 는 처리 요구량이 증가할경우 Shard를 동적으로 스케일 아웃, 스케일 인 할수있습니다.
        - Kafka는 처리 요구량이 증가할 경우 Broker를 추가하면 수평적으로 확장할수있습니다.
    - 중앙 역할을 하는 노드
        - Kinesis 와 Kafka 모두 중앙집중형 데이터 스트리밍 서비스입니다.
    - 데이터 분배와 매칭
        - Kinesis
          - 하나의 Consumer가 여러 Shard를 처리 가능합니다.
          - 하나의 Shard는 하나의 Consumer와 매칭됩니다.
        - Kafka
          - 하나의 Consumer가 여러 Partition을 처리 가능합니다.
          - 하나의 Partition은 하나의 Consumer와 매칭됩니다.

- 차이점
    - 관리 주체
        - Kinesis는 AWS에서 완전관리되는 클라우드 서비스입니다.
        - Kafka는 실제 물리적 서버나 컨테이너에 설치해야하며, 사용자가 직접 운영해야는 온프레미스 서비스입니다.  
    - API 모델
        - Kinesis는 AWS SDK 나 API Gateway를 사용해야 합니다.
        - Kafka는 프로듀서/컨슈머에서 사용하는 오픈소스 sdk를 사용해야 합니다.
    - 비용 구조
        - Kinesis는 Shard 단위로 활성화 된 숫자와 데이터 처리량에 따라 과금됩니다.
        - Kafka는 자체 구축한 서버위에서 돌아가기 때문에 서버 운영 비용이 청구됩니다.
    - 데이터 보존 및 처리 방식
        - Kinesis는 데이터를 순차적으로 보관하며, 기본 보존 기간은 24시간(최대 7일)입니다. 
          - 데이터는 기본적으로 소비 후 제거되지만, Data Streams를 통해 이벤트를 재처리 가능합니다.
        - Kafka는 데이터를 Partition에 보존하며, 보존 기간은 사용자가 설정합니다.
          - 데이터는 Consumer가 Offset으로 관리하여 재처리와 과거 데이터 조회가 쉽습니다.


상황에 따라 어떤걸 사용해야할지 모르겠지만, 

온프레미스 환경이나 멀티클라우드 환경에서 사용해야 하는 경우 & 자유로운 커스터마이징과 유연성이 중요한 경우 -> **kafka**

AWS 중심의 생태계를 사용하는 경우 & S3, Redshift 등 AWS 데이터 저장소와 통합이 중요한 경우 -> **presto**

일 것 같습니다..